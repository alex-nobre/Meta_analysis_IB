---
title: "Analysis notebook"
output: html_notebook
---

This notebook details steps and decisions for the analysis of quantitive data in the meta-analysis.

Legends:

IB = inattentional blindness;
US = unexpected stimulus/stimuli;


Each experiment can contribute with one or more effect sizes/tests, one in each line. Each one of those is called a contrast.


# Implicit Effect size computations
We compute effect sizes based on available data from the papers. From the papers included after full-text reading, the following did not present enough data to allow the computation of an effect-size:
 
 * Lathrop et al. (2011)
 * Scholte et al. (2006) - MEG
 
These were considered only in the qualitative, but not in the quantitative analysis.

Effect sizes need a direction. Otherwise, if only the absolute value of the difference is recorded, all data points in the funnel plot will necessarily appear in the right side of the plot.

In our analysis, since there is no treatment/control group, we have to choose an experimental condition and a control condition to decide the direction. Our options are:

* When a study mentions a critical trial and a control trial, those are the experimental and the control conditions, respectively;
* When the above is not mentioned, but it is clear that in one condition there is an US, and the other does not, the first is the experimental condition, the second is the control;
* When a configuration is the US (e.g., grouping), the condition with the configuration is the experimental condition, the other is the control condition

Problem:in some cases, smaller RTs result from implicit processing (e.g., orienting of attention by arrows - Gabay); in others, larger RTs result (e.g., amodal completion of dashed lines - Moore and Egeth, 2003).  So we cannot simply subtract experimental - control, because this will result in effects in both directions meaning the same thing


* Alternative:

- Code effects in the direction of facilitation as positive and effects in the direction of no facilitation (these will most likely be nonsignificant, but what matters is their contribution for the meta-analytic effect size) as negative.

- For interactions: when the interaction between V1 and V2 does not indicate a reversal in the direction of the effect of levels of V2 across levels of V1, the direction of the effect shown by the interaction is the same as the direction of the effect of V2.


Are there any studies which do these criteria do not contemplate?

* What about when it is a comparison against chance? - deviations above chance mean a difference in the direction of facilitation, thus positive; below chance (also in this case, most likely nonsignificant) as no facilitation, thuss negative.

Whenever an implicit effect is computed from proportions or percentages:

* success = participant displayed the effect
* failure = participant did not display the effect

## 1. Ariga et al. (2008)

## 2 to 5. Beanland and Pammer (2011)

Each condition (eyes-fixating x eyes-moving in exp. 1A, slow-US x fast-US in exp. 2) is a separate contrast, so each should be coded in a separated line.

Should we average the mean and sd of accuracy across critical trials (3 and 5) and control trials (2 and 4)? 

First, there is a difference in the degree of awareness: For non-noticers only, this is ok, since trials don't differ in awareness. For noticers, this would be problematic, since this group includes both individuals who noticed the US in the first critical trial and those who didn't.

If we only analyze non-noticers processing, this should not be a problem. Since implicit processing effects are computed from non-noticers only, we can average trials for them without resulting in mixing explicit and implicit effects. This demands that the implicit group be composed only of participants who did not notice the US in either the first or the second critical trial.

There is still the issue of repeated exposition, which differs between the first and second critical trials. In a lot of studies, we have multiple critical trials, in others, only one. Considering that we don't have access to single-trial data in most studies, I propose we do average the critical trials. This can be used later to compare power between studies with distinct numbers of critical trials. To analyze averaged trials, we need the combined means and standard deviations of both control trials averaged and both critical trials averaged. These can be computed from the raw data sent by Beanland.

- Exp. 1A: Table 2 on page 981.

- Exp. 2: Table 8 on page 986.

## 12. & 13. Moore and Egeth, exps. 1 and 3

Experiment 2 is not included because it aims only at eliminating a visual confound; it does not include the illusion.

The effect of the background on the responses is given by the percentage of subjects who responded according to the illusions (Ponzo illusion in exp. 1, MÃ¼ller-Lyer illusion in exp. 3), compared with chance:

- Exp. 1: "inattention block" data on page. 345

- Exp. 3: "inattention block" data on page. 349

## 14. Moore et al. (2003)


## 15. to 19. Razpurker-Apfeld et al. (2008)

Each condition (column/row vs. triangle/arrow) is treated as a separate constrast. 

-RT: Implicit processing is indicated by the congruence effect, which is indicated by an interaction (better performance in same trials during same-backgrounds trials and better performance in different trials during different-background trials).
The direction of the interaction is determined as explained above.

- d': Implicit processing is the difference between d' in same and different background conditions. d' = hit - false alarms in different trials. If d' is positive, effect is facilitatory (hits > false alarms), so the effect size is also positive; otherwise, the effect size is negative.


## 20. & 21. Richards et al. (2012)

Data comes from page 174 in the paper, on Table 1, only from "IBs" participants. Lines from the inspection screen stage are not included because this stage does not include the US (red cross). Two options for effect:

 - Number of participants fixating on the US is above chance; or
 
 - Difference in fixations and in gaze time between IBs who fixate the US and those who don't.
 
We can also split the sample between subsamples, each forming a contrast.
 
 
## 22. to 26. Russel and Driver (2005)

Similar to Razpurker-Apfeld et al. (2008).

Exp. 1, acc: interaction significant, positive sign because effect is facilitatory

Exp. 1, RT: interaction non-significant, positive sign because effect is facilitatory

Exp. 2, acc: interaction significant, positive sign because effect is facilitatory

Exp. 2, RT: interaction non-significant, positive sign because effect is facilitatory

Exp. 3, acc: interaction significant, positive sign because effect is facilitatory

Exp. 3, RT: interaction non-significant, positive sign because effect is facilitatory

Exp. 4A, acc: interaction significant, positive sign because effect is facilitatory

Exp. 4A, RT: interaction non-significant, but data not available to compute effect size

Exp. 4A, acc: interaction significant, positive sign because effect is facilitatory

Exp. 4B, RT: interaction non-significant, but data not available to compute effect size

Exp. 5, acc: interaction significant, positive sign because effect is facilitatory

Exp. 5, RT: interaction non-significant, positive sign because effect is facilitatory

## 27. Shafto and Pitts (2015)

Effect is computed from the t-value and corresponding df from Phase 1, in IB group. Effect is non-significant, and negative.


## 28. & 29. Schnuerch et al. (2016) exps. 1 and 2.

Difference between incongruent and neutral trials in RT, which tests the hypothesis. Both effects are significant and facilitatory, thus have a positive sign.

Computed Cohen's d in experiment is different from reported Cohen's d (0.43). Which to keep?


## 30. Scholte et al. (2006)

There are multiple contrasts, for v1, v2, v3, and v4/v8. Should all of them be separated?

- Exclude - not behavioral

## 31. Vandenbroucke et al. (2014)

- Exclude - not behavioral

## 32. Wiemer et al. (2013)

Difference between SCRs evoked by flower stimuli and spider stimuli (p.161). The effect is facilitatory - thus, the sign is positive - and significant.

Design in between-subjects.

Degree of freedom is decimal?? Round down?

- Exclude - not behavioral


## 33 to 35. Mack and Rock's experiments from chapter 8

### Exp. 1 - p. 178-179

Use reported number of subjects who offered prime word as stem-completion in the priming experiment and in the control experiment; build a contingency table with the proportions; and compute chi-squared from the contingency table.

In figure 1, reported percentage of participants who offered the words as stem completion does not match the n reported in the text on page 179; using percentages to compute proportions instead.

### Exp. 2 - p. 182

Use reported number of subjects who offered prime word as stem-completion in the priming experiment and in the control experiment; build a contingency table with the proportions; and compute chi-squared from the contingency table.

### Exp. 3 - p. 184

Use reported number of subjects who offered prime word as stem-completion in the priming experiment and those in the control experiment who were presented roots for the same words as in exp 3 (short and flake) shown in figure 1 (p. 178), to control for stimulus properties like frequency; build a contingency table with the proportions; and compute chi-squared from the contingency table.

In figure 1, reported percentage of participants who offered "short" as stem completion + those who offered "flake" does not match the n reported in the text on page 179; using percentages to compute proportions instead.

### Exp. 4 - p. 187-188

Use reported number of subjects who offered prime word as stem-completion in the priming experiment and in the control experiment; build a contingency table with the proportions; and compute chi-squared from the contingency table.

Reported chi-square value was incorrect (14.54, p.188).

### Exp. 5 - p. 191

Use reported number of subjects who offered prime word as stem-completion in the priming experiment and in the control experiment; build a contingency table with the proportions; and compute chi-squared from the contingency table.


## Compute correlation to calculate variance of d for hedge's g

Two datasets are available to compute the correlation estimate: Razpurker-Apfeld et al. (2004) and Schnuerch et al. (2016).

# Awareness effect sizes computations

Whenever awareness is computed from proportions or percentages:

* success = participant was aware
* failure = participant was unaware

## 1. Ariga et al. (2008)

## 2 to 5. Beanland and Pammer (2011)

Since for the implicit processing effect sizes we considered only participants who were IB in both trials, and the goal of using awareness effect sizes is to assess the power of awareness measures, we adopted a conservative threshold and considered a success any participant who notices the US in either the first or the second critical trial.

## 11 & 12. Moore and Egeth, exps. 1 and 3

Use of direct query instead of forced-choice, since this can be performed using implicit knowledge

* Exp. 1: p. 345

* Exp. 3: p. 349

Effect sizes computed using percentage of noticers given

Result is infinite, so replace with largest effect in data

## 13. Moore et al. (2003)

Use question about regularity (p. 312), instead of orientation (p. 313), since the former assesses perception more generally and thus might be more sensitive

Use reported percentage of noticers. However, because there were 0 noticers, the ES in inf. Therefore, we replaced the value for this contrast with the largest value among other contrasts.

## 14. Moore et al. (2004)

Use of direct query (714) instead of forced-choice for awareness effect, since this can be performed using implicit knowledge

Effect size is computed from given percentage of noticers.

## 15. Most et al. (2004)

### Exp. 1 - p. 228

Use reported sum of number of noticers across conditions as successes and total n across conditions as population. Although this mixes distinct rates of noticing in distinct conditions, this is coherent with how the implicit effect sizes were reported in experiment eight, where conditions are also mixed.

### Exp. 2 - p. 229

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.

### Exp. 3 - p. 229 (rates), 230 (total n)

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.

### Exp. 4 - p. 229 (rates), 231 (total n)

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.

### Exp. 5 - p. 229 (rates), 233 (total n)

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.

### Exp. 6 - p. 229 (rates), 233 (total n)

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.

### Exp. 7 - p. 229 (rates), 234 (total n)

Use reported percentage of noticers in each condition to compute n of noticers, and sum results to obtain n of successes.


## 16. Razpurker-Apfeld et al. (2008) 

Use reported number of noticers (p. 188) and total n (p. 185) to compute chi-square. Two distinct effect sizes are computed by condition; within the same condition, the effect size is the same for RT and d', since it is the same sample. They are coded as separate cohen's d because RT and d' are separate entries (lines) in the table.

## 17. Richards et al. (2012)

Use reported percentage of noticers (p. 173) to compute n of noticers.

## 18. Russel and Driver (2005), exps. 1-5

### Exp. 1 - p. 610

Use reported n of noticers to compute chi-squared.

### Exp. 2 - p. 611

Use reported n of noticers to compute chi-squared.

### Exp. 3 - p. 613

Use reported n of noticers to compute chi-squared.

### Exp. 4A - p. 614-615

Use reported n of noticers to compute chi-squared.

### Exp. 4B - p. 615

Use reported n of noticers to compute chi-squared.

### Exp. 5 - p. 618

Use reported n of noticers to compute chi-squared.

## Mack and Rock's experiments from chapter 8

### Exp. 1 - p. 178

Use reported number of unaware subjects to compute proportions.

### Exp. 2 - p. 182

Use reported number of unaware subjects to compute proportions.

### Exp. 3 - p. 184

Use reported number of unaware subjects to compute proportions.

### Exp. 4 - p. 187

Use reported number of unaware subjects to compute proportions.

## 19. Shafto and Pitts (2015) - p. 10943

Use reported number of inattentionally blind subjects.

## 20. Wiemer et al. (2013) - p. 160

Use of percentage of noticers by condition to compute proportions, sum across conditions and compute chi-squared.


# Calculation of effect sizes for model

We chose to use hedge's g as standardized effect size. We computed hedge's g using formulas for matched groups from Borenstein's introduction to meta-analysis (2009), pp. 25-30.

# Meta-analytic model

## Moderation

We have the following variables to conduct moderation analysis so far for the implicit effects:

* Measure: RT vs accuracy

* Relevance: irrelevant vs. relevant

* N of trials - this needs to be done with a regression, using n of trials as a continuous predictor

* Run moderator analysis for inattention paradigm

* Run moderator analysis for papers performing group assessment of awareness instead of inattetion paradigm - Alex

Perform analysis within subgroups and then comparisons between subgroups


# Heterogeneity

xzDRRRRRRRRRRRRRRRRRRRRRRRRRRRFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFDDDDDDDDDDDDDDDDDDDDDDDDDDCVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa


-----------------------------------------------------------------------------------
Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
